---
title: "Survival Analysis of Post-Myocardial Infarction Patients"
author: "Alvein, Orr, Pham"
date: "5/22/2020"
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.height=4.5, fig.width=7)

library(readxl)
library(knitr)
library(tidyverse)
library(dplyr)
library(kableExtra)
library(survival)
library(survminer)
library(ggplot2)
library(VIM)
library(missForest)
library(ggplot2)
library(ggpubr)

df = data.frame(read_excel("df.xlsx"))
df[df=="?"] = " "

df.new = data.frame(read_excel("df.new.xlsx"))

s.df = Surv(df.new$Survival,df.new$Status)
```


# Abstract

### Background
$\textbf{Background:}$ The rates of myocardial infarction is becoming an increasing common occurence in the United States. Rapid development of medical technology and knowledge have led to an decline in myocardial infarction fatalities (Gu, et al 1999). However, there is much to be learned regarding the survival probabilities of patients following an infarction episode.Some studies have already examined the effects of externalities on the survival rates of these patients (Rimm, et al. 1995).

### Objectives
Our goal is to provide detailed survival statistics of patients during a post-myocardial infarction time period with specific concern addressed to age, ventricular activity, and physiological cardic state. Using these variables,  we aim to provide succinct information on the current state of the dataset as well as provide robust predictors for the future estimates of survival for future patients.

We aim to fit non-parametric (Kaplan-Meier) and parameters curves to describe the data as well as choose a regression model to be used for predictive surviability. 

### Methods
Data from 133 post-myocardial infarction patients measure the time in months until death in a one year monitoring period of follow-up. We use a combination of nonparametric (Kaplan-Meier) and parametric methods (Weilbull, Log-Normal, Log-Logistic, Cox PH) to determine estimates of survival among gender and physiological cardic state (contraction depth, muscular activity, anatomical status). We fit multiple distributions over the dataset to provide current-state information of the patient dataset. Then, we regress multiple models and use combination of Akaike Information  (AIC) statistics, logistic ratio tests, and residual analysis to determine model adequacy. 

### Results
Initial non-parametric Kaplan-Meier curve shows a median survival time of ~30 months for all age groups. We choose a Weibull regression fit (tenative) for predictive model as we have favorable AIC, ratio, and residual indicators out of all of our model.

### Conclusion
Thus, for predictive model we found the Weibull regression fit to be the most ideal candidate for modeling survivability for patient groups. Additionally, when examining the survival times for the Kaplan-Meier step curve, we see that the younger age groups do survive as well as their older counterparts. Given our limited sample size for that population, we recommend continued studies into external effects of the post-mycardial episode survival.



# Introduction

Heart disease has become the leading cause of US deaths among all racial and ethnic groups (Heron 2019, Fryar 2012). In 2009 cardiovascular disease represented nearly 64% of all cardiac related deaths (Dalen, et. Al. 2014). These myocardial infarctions – commonly known as heart attacks - are becoming largely common among all U.S. demographic populations. As such, researchers are looking to understand the underlying causes of these episodes. Specifically, increases in cardiovascular disease (CVD) cases have been largely attributed to many risk factors such as high levels of low-density lipoproteins (LPL), high blood pressure, and smoking (Fryar 2012). 

These variables are often the results of lifestyle choices and effects of poverty. The prevalence of the disease has closely been followed a large body of conducted researchers aiming to reduce either the number of these cases or reduce the mortality of the specific myocardial infarction rates. Between 1980 and 2002, mortality rates saw a decrease of approximately 49% (Wilmot 2015). Decreases in mortality was common through the world better medical intervention techniques and increase awareness of healthier lifestyle choices became more prevalent (Goldman, et al. 1984).	

Unsurprisingly, as more patients survive CVD related infarction episodes, more detail has been paid to understand the survivability the time period following an episode. Wall motion score (a measure of heart contractility during cycling) was significantly higher in those that survived versus those that died (Kan, et. Al. 1986). We hope to examine several factors that determine survivability among these patients. In addition to wall motion score, we hope to stratify and understand the relationships between time to event (death) measurements compared to general heart health and age. Our goal is to describe the survivability of our dataset and provide a model to predict the factors that determine survability in the one-year period following a myocardial infarction episode.


# Dataset

Our data was obtained our data set from Kaggle via the Reed Institute. The data set contains 133 total patient observations across 8 variables: status at the end of the survival period, age, presence of pericardial effusion, fractal shortening, epss, wall motion score, wall motion index, and alive at the end of one year. Three patient survival times were not given; thus, we elected to remove those values to develop the most accurate portrayal of survival times. 

Since the time of myocardial infarction varies (depending if a patient joined the study prior to the starat), some patients were followed for less than a year. This provides a clear censoring and truncation. We discuss the nature of censoring in the following section.

At this point, 40 points of data were missing from the total dataset. A random forest algorithm (see: missForest package) was employed to iteratively impute values. With this in mind, our predictive and summary models will have less than ideal accuracy.

We then classify continuous variables into groups for stratification. 

Age is divided into three groups with 0 denoting younger than 55 years, 1 denoting 55 to 70 years, and 2 denoting older than 70 years. Pericardial effusion is already grouped into binary values with 0 denoting the absence of fluid while 1 denotes the presence of the effusion. Finally, wall motion score is divided into three groups: 0 denoting scores less than 12, 1 denoting scores of 12 - 17, and 2 denoting scores greater than 14. These groups are summarized in the table below:

```{r groupings.table, echo=FALSE, warning=FALSE, message=FALSE, results='asis'}

Indicator = c("0","1","2")
Age = c("< 55 Years", "55-70 Years", "> 70 Years")
Effusion = c("Fluid is absent", "Fluid is present","")
WMS = c("< 12", "12-14", "> 14")

groupings = data.frame(Indicator, Age, Effusion, WMS)
groupings

kable(groupings, caption="Stratification Groupings") %>%
  kable_styling(position = "center", latex_options="hold_position")

```

The reader may find a summary of tables and original dataset in the appendix of this paper.

### Imputation

In addition to the two rows that we removed, we further modified the dataset. The provided data contains 40 missing values that we chose to impute using the random forest algorithm methods in the missForest R package. Below is a summary of the missing data:

```{r missing.table, echo=FALSE, warning=FALSE, message=FALSE, results='asis'}

missing.data = aggr(df) #visualize the missing information

kable(missing.data$missings, caption="Missing Values in Original Dataset") %>%
  kable_styling(position = "center", latex_options="hold_position")

```

We leverage the missForest package that uses algorithmic process used here uses a modified k-nearest neighbot (KNN) approach. Using a training data set, the routines of the algorithm predicts the missing values trained on the observed parts of the dataset (Stekhoven 2012). The process checks each iteration for an acceptable amount of error. If an iteration produces an error that is smallest than that last iteration, then the algorithm continues to function. This progress stops when an error is larger than the previous iteration. Refer to Stekhoven, et. al 2012 for more detail. 

We used the missFortune package to run up to 500 iterations. Each iteration was allotted 1000 trees for the random forest algorithmic approach.

Following imputation, we verify the imputation accuracy using the normalized root mean squared error as an indicator of accuracy (NRMSE, Oba et al. (2003)). The general performance of our imputated dataset can be expressed by:

\[ NRMSE\ =\ \sqrt{\frac{mean\left(\left(X^{true}-X^{imp}\right)^2\right)}{var\left(X^{true}\right)}} \]

Where X is a matrix of our dataset. Being a random forest iterative process, each imputed dataset will be different from each other. For our particular seed and iterations, we aobtained a NRMSE value of 0.1442 - that is our inputted values have an estimate 14.42% deviation from estimated true accuracy.

The full imputed dataset may be found in the appendix of this paper. As well as references to the authors who created the algorithm.

### Censoring

Our dataset has numerous censored valued - that is, valued that cannot be recorded due the constrainst of the study design. In our data set, we are exmaining the survival after a heart attack, that is, the event of interest is death given that a patient has had already survived a heart attack (left truncation).

We have fixed start and end dates for when the data was collection. Some patients joined when the study began. Others joined later after the start date. Because of this, we cannot accurately determine how long a patient survived after our observation period is over. In addition, there are some patients that have been lost to follow up or may have died due to the onset of other unrelated factors. These data present themselves as being randomly right censored.


# Methodology

Here, we briefly review the methodology and theory behind our analysis techniques for context.

## Non-Parametric: Kaplan Meier

We use Kaplan-Meier (KM) survival estimators to model a step curve for the survival of our censored dataset. The KM estimator is an adjustment of an empirical survival function to reflect the presence of right-censored observations (Tableman & Kim, 2004). The estimator can be described in the following equation:

\[ \hat{S}(t) = \prod_{y_{(i)}\leq{t}}^{k} p_i = \prod_{i=1}^{k} (\frac{n_i -d_i}{n_i}) \]

Where $ n_i $ is the number alive before time $ y_i $ and $ d_i $ is the number of events during during that interval. In our case, $ y_i $ is the specific patient being observed, $ n_i $ is the number of patients alive at time $ y_i $. With $ k = 131 $, our KM equation is:

\[ \hat{S}(t) = \prod_{i=1}^{131} (\frac{n_i -d_i}{n_i}) \]

We use this equation to estimate the survival at each time interval. We conduct this analysis for the whole data set and then choose to stratify on age, pericadial effusion presence, and wall motion score. We also include cumulative hazard estimators based on the KM fit.

### Cumulative Hazard Estimators

We calculate the hazard of our Kaplan-Survivor function by using Nelson-Aalen's hazard estimate. 

\[ \tilde{H}(t) = \sum_{y_{(i)}\leq{t}} \frac{d_i}{n_i}  \]

Where $ d_i_ $ is the number of events during each interval and $ n_i $ is the number alive before each time. The variance of the Nelson-Aalen's hazard estimate can be found as follows:

\[ var(\tilde{H}(t)) = \sum_{y_{(i)}\leq{t}} \frac{d_i}{{n_i}^2}\]

Nelson-Aalen's hazard estimate is an approximatation of the standard cumulative hazard estimate (shown below):

\[ \hat{H}(t) = -log \prod_{y_{(i)}\leq{t}} \frac{d_i - n_i}{n_i}  \]

The Nelson-Aalen estimate approximation is exceptionally effective as the estimate sums the hazard from each interval step. Thus, producing an effective substitution of the observed cumulative hazard product sum shown above. We just Nelson-Aalen to estimate the hazard for each of our non-parametric stratification.

## Parametric Estimates: Log-Normal Distribution



## Parametric Estimates: Log-Logistic Distribution



## Parametric Estimates: Weibull Distribution



## Hazard Estimates 



## Regression & Model Selection







# Results

## Exploratory Data Analysis




## Non-Parametric: Kaplan-Meier Survival Estimates

Output from our Kaplan-Meier estimators give us the following curve (full KM estimator table can be found in the appendix).

```{r km.all, fig.align='center', echo=FALSE}
km.plots = list()
km.all = survfit(s.df~1,type="kaplan-meier", data=df.new)
km.plots[[1]] = ggsurvplot(km.all, 
           palette = "#2E9FDF", 
           conf.int = TRUE, 
           title="Post-Myocardial Infarction Survival", 
           subtitle="All Groups",
           font.title=c(12,"bold.italic"),
           font.subtitle = c(10,"italic"),
           font.x = c(9, "bold.italic"),
           font.y = c(9, "bold.italic"),
           ylab="Surival Proportion", 
           xlab="Time to Death (Months)",
           surv.median.line = "hv",
           legend.title = "Groups",
           legend.labs = "All")


km.age = survfit(s.df~Age.s, type="kaplan-meier", data = df.new)
km.plots[[2]] = ggsurvplot(km.age, 
           palette = c("darkcyan","darkgoldenrod3","darkorange3"), 
           title="Post-Myocardial Infarction Survival", 
           subtitle="Stratified by Age Group",
           font.title=c(12,"bold.italic"),
           font.subtitle = c(10,"italic"),
           font.x = c(9, "bold.italic"),
           font.y = c(9, "bold.italic"),
           ylab="Surival Proportion", 
           xlab="Time to Death (Months)",
           surv.median.line = "hv",
           legend.title = "Groups",
           legend.labs = c("< 55 Year","55 - 65 Years","> 65 Years"))

km.effusion = survfit(s.df~P.Effusion, type="kaplan-meier", data = df.new)
km.plots[[3]] = ggsurvplot(km.effusion, 
           palette = c("darkcyan","darkgoldenrod3"), 
           title="Post-Myocardial Infarction Survival", 
           subtitle="Stratified by Presence of Pericardial Effusion",
           font.title=c(12,"bold.italic"),
           font.subtitle = c(10,"italic"),
           font.x = c(9, "bold.italic"),
           font.y = c(9, "bold.italic"),
           ylab="Surival Proportion", 
           xlab="Time to Death (Months)",
           surv.median.line = "hv",
           legend.title = "Groups",
           legend.labs = c("Present","Absent"))

km.wmi = survfit(s.df~WMS.s, type="kaplan-meier", data = df.new)
km.plots[[4]] = ggsurvplot(km.wmi, 
           palette = c("darkcyan","darkgoldenrod3","darkorange3"), 
           title="Post-Myocardial Infarction Survival", 
           subtitle="Stratified by Wall Motion Index",
           font.title=c(12,"bold.italic"),
           font.subtitle = c(10,"italic"),
           font.x = c(9, "bold.italic"),
           font.y = c(9, "bold.italic"),
           ylab="Surival Proportion", 
           xlab="Time to Death (Months)",
           surv.median.line = "hv",
           legend.title = "Groups",
           legend.labs = c("< 12", "12-14", "> 14"))


arrange_ggsurvplots(km.plots, print=TRUE, ncol=2, nrow=2)

```

Here is the survival curve for all groups within our dataset. With time spanning to a maximum of 57 months, we have  a mean survival time of approximately 30.5 months. The median survival time is approximately 29 months a 95% lower and upper confidence limits of 27 and 33 months, respectively.  We see that a majority of our censored values have very short survival times. This is an intuitive finding as patients who joined the study late have relatively unknown survival (hence, their right censored nature. A summary of the results from our KM fit is below:

```{r km.summary, fig.align='center', echo=FALSE, results = 'asis'}
km.all.summary = data.frame(t(summary(km.all)$table))
km.as = km.all.summary[,c(1,4,5,7,8,9)]
colnames(km.as) = c("Records","Events","Mean","Median","Median 0.95 LCL","Median 0.95 UCL")

kable(km.as, caption="Kaplan-Meier Results") %>%
  kable_styling(position = "center", latex_options="hold_position")
```

- Add stratified on age

- Add pericardial effusion

- Add stratified on cardiac physiology


## Parametric: Log-Normal Model

```{r ln.plot, echo=FALSE}

```





## Parametric: Log-Logistic Model

```{r ll.plot, echo=FALSE}

```






## Parametric: Weibull Model

```{r wb.plot, echo=FALSE}

```







## Cox Proportional Hazard

```{r coxph.plot, echo=FALSE}

```

## Model Diagnostics






### AIC, BIC, and Confidence Intervals

```{r diagnostic.table, echo=FALSE}

```

### Residual Analysis/QQ Plot

```{r diagnostic.resid, echo=FALSE}

```

```{r diagnostic.qqplot, echo=FALSE}

```

# Discussion

\newpage

# Appendix

## References

Andrikopoulos, G. K., Tzeis, S. E., Pipilis, A. G., Richter, D. J., Kappos, K. G., Stefanadis, C. I., … Chimonas, E. T. (2006). Younger age potentiates post myocardial infarction survival disadvantage of women. International Journal of Cardiology, 108(3), 320–325. doi: 10.1016/j.ijcard.2005.05.016

Fryar CD, Chen T-C, Li X. Prevalence of uncontrolled risk factors for cardiovascular disease: United States, 1999–2010 pdf icon[PDF-494K]. NCHS data brief, no. 103. Hyattsville, MD: National Center for Health Statistics; 2012. Accessed May 9, 2019.

Ford, E. S., & Capewell, S. (2007). Coronary Heart Disease Mortality Among Young Adults in the U.S. From 1980 Through 2002. Journal of the American College of Cardiology, 50(22), 2128–2132. doi: 10.1016/j.jacc.2007.05.056

Goldman, L. (1984). The Decline in Ischemic Heart Disease Mortality Rates. Annals of Internal Medicine, 101(6), 825. doi: 10.7326/0003-4819-101-6-825
Gu K, Cowie CC, Harris MI. Diabetes and Decline in Heart Disease Mortality in US Adults. JAMA. 1999;281(14):1291–1297. doi:10.1001/jama.281.14.1291
Heron, M. Deaths: Leading causes for 2017 pdf icon[PDF – 3 M]. National Vital Statistics Reports;68(6). Accessed November 19, 2019.

Kan, G., Visser, C., Kooler, J., & Dunning, A. (1986). Short and long term predictive value of wall motion score in acute myocardial infarction. British Heart Journal, 56, 422-427.
Oba S, Sato MA, Takemasa I, Monden M, Matsubara K, Ishii S. A Bayesian missing value estimation method for gene expression profile data. Bioinformatics. 2003;19(16):2088‐2096. doi:10.1093/bioinformatics/btg287

Rimm, E. B., Stampfer, M. J., Giovannucci, E., Ascherio, A., Spiegelman, D., Colditz, G. A., & Willett, W. C. (1995). Body Size and Fat Distribution as Predictors of Coronary Heart Disease among Middle-aged and Older US Men. American Journal of Epidemiology, 141(12), 1117–1127. doi: 10.1093/oxfordjournals.aje.a117385 

Salzberg, S. (1988). Exemplar-based learning: Theory and implementation (Technical Report TR-10-88). Harvard University, Center for Research in Computing Technology, Aiken Computation Laboratory (33 Oxford Street; Cambridge, MA 02138).

Sia, Y. T., Parker, T. G., Liu, P., Tsoporis, J. N., Adam, A., & Rouleau, J. L. (2002). Improved post-myocardial infarction survival with probucol in rats: Effects on left ventricular function, morphology, cardiac oxidative stress and cytokine expression. Journal of the American College of Cardiology, 39(1), 148–156. doi: 10.1016/s0735-1097(01)01709-0

Stekhoven, D. J., & Buhlmann, P. (2011). MissForest--non-parametric missing value imputation for mixed-type data. Bioinformatics, 28(1), 112–118. doi: 10.1093/bioinformatics/btr597 

Tableman, M., & Kim, J. S. (2004). Survival analysis using S: analysis of time-to-event data. Boca Raton, Florida: Chapman & Hall.

Wilmot, K. A., O’Flaherty, M., Capewell, S., Ford, E. S., & Vaccarino, V. (2015). Coronary Heart Disease Mortality Declines in the United States From 1979 Through 2011CLINICAL PERSPECTIVE. Circulation, 132(11), 997–1002. doi: 10.1161/circulationaha.115.015293


\newpage


## Dataset Variable Summary

```{r Dataset.summary, echo=FALSE, results='asis'}

df.sum = data.frame(read_excel("df.sum.xlsx"))

kable(df.sum, "latex", 
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "\\addlinespace",
      caption = "Summary of Dataset Covariates") %>%
  kable_styling(latex_options = c("hold_position","repeat_header"),
                full_width = TRUE)

```


## Original Dataset

```{r Dataset.actual, echo=FALSE, results='asis'}

kable(df, "latex", 
      booktabs = TRUE,
      longtable = TRUE,
      caption = "Original Dataset") %>%
  kable_styling(latex_options = c("hold_position","repeat_header"),
                full_width = TRUE)
```

\newpage

## Imputed Dataset

```{r imp.table, echo=FALSE, results='asis', warning=FALSE, message=FALSE}

round_df <- function(x, digits) {
    # round all numeric variables
    # x: data frame 
    # digits: number of digits to round
    numeric_columns <- sapply(x, mode) == 'numeric'
    x[numeric_columns] <-  round(x[numeric_columns], digits)
    x}

df.new = round_df(df.i$ximp,2)

kable(df.new, "latex", 
      booktabs = TRUE,
      longtable = TRUE,
      caption = "Imputed Dataset") %>%
  kable_styling(latex_options = c("hold_position","repeat_header"),
                full_width = TRUE)

```

\newpage

## Table of Kaplan-Meier Estimators

```{r km.table, echo=FALSE, results='asis', warning=FALSE, message=FALSE}

km.sum = data.frame(km.all$n.risk, km.all$n.event, km.all$n.censor, km.all$surv, km.all$std.err, km.all$lower, km.all$upper)

kable(km.sum, 
      caption="Kaplan-Meier Estimate Summary",
      col.names = c("Ni","Di","Ci","Survival","Std. Err", "95% LCL", "95% UCL")) %>%
  kable_styling(latex_options = "hold_position")

```

\newpage

## R Code

```{r ref.label=knitr::all_labels(), echo = T, eval = F}
```

